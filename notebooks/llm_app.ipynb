{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import evaluate\n",
    "from rouge_score import rouge_scorer\n",
    "from enum import Enum\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, PromptTemplate, LLMChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "from langchain.chains import LLMSummarizationCheckerChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChainTypes(Enum):\n",
    "    STUFF = 0\n",
    "    MAP_REDUCE = 1\n",
    "    REFINE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summarization:\n",
    "    def __init__(\n",
    "        self,\n",
    "        temperature=0,\n",
    "        model_name=\"text-davinci-003\" # gpt-3.5-turbo\n",
    "    ):\n",
    "        self.llm = OpenAI(\n",
    "            temperature=temperature,\n",
    "            model=model_name\n",
    "        )\n",
    "    \n",
    "    def textsplitter(self):\n",
    "        return RecursiveCharacterTextSplitter(\n",
    "            chunk_size=300,\n",
    "            chunk_overlap=50,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \"\\t\"]\n",
    "        )\n",
    "    \n",
    "    def load_data(self, filename):\n",
    "        with open(filename) as f:\n",
    "            texts = f.read()\n",
    "        \n",
    "        return texts\n",
    "    \n",
    "    def create_docs(self, texts):\n",
    "        text_splitter = self.textsplitter()\n",
    "        texts = text_splitter.split_text(texts)\n",
    "        docs = [Document(page_content=t) for t in texts]\n",
    "        return docs\n",
    "    \n",
    "    def generate_prompt(self):\n",
    "        prompt_template = \"\"\"You are a humanitarian analyst and has a strong domain knowledge. \n",
    "        Write a concise summary of the following including key points by answering following questions\n",
    "\n",
    "        {text}\n",
    "\n",
    "        CONCISE SUMMARY:\n",
    "        \"\"\"\n",
    "\n",
    "        prompt = PromptTemplate(\n",
    "            template=prompt_template,\n",
    "            input_variables=[\"text\"]\n",
    "        )\n",
    "        return prompt\n",
    "\n",
    "    def generate_refine_prompt(self):\n",
    "        refine_template = (\n",
    "            \"Your job is to produce a final summary\\n\"\n",
    "            \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "            \"We have the opportunity to refine the existing summary\\n\"\n",
    "            \"(only if needed) with some more context below.\\n\"\n",
    "            \"----------------\\n\"\n",
    "            \"{text}\\n\"\n",
    "            \"----------------\\n\"\n",
    "            \"Given the new context, refine the original summary\\n\"\n",
    "            \"If the context isn't useful, return the original summary\"\n",
    "        )\n",
    "        refine_prompt = PromptTemplate(\n",
    "            template=refine_template,\n",
    "            input_variables=[\"existing_answer\", \"text\"]\n",
    "        )\n",
    "        return refine_prompt\n",
    "\n",
    "    def generate_summary(\n",
    "        self,\n",
    "        docs,\n",
    "        prompt,\n",
    "        chain_type=ChainTypes.STUFF,\n",
    "        verbose=False\n",
    "    ):\n",
    "        if chain_type==ChainTypes.MAP_REDUCE:\n",
    "            chain = load_summarize_chain(\n",
    "                llm=self.llm,\n",
    "                chain_type=\"map_reduce\",\n",
    "                verbose=verbose,\n",
    "                map_prompt=prompt,\n",
    "                combine_prompt=prompt\n",
    "            )\n",
    "        elif chain_type==ChainTypes.REFINE:\n",
    "            chain = load_summarize_chain(\n",
    "                llm=self.llm,\n",
    "                chain_type=\"refine\",\n",
    "                verbose=verbose,\n",
    "                question_prompt=prompt,\n",
    "                refine_prompt=self.generate_refine_prompt()\n",
    "            )\n",
    "        else:\n",
    "            chain = load_summarize_chain(\n",
    "                llm=self.llm,\n",
    "                chain_type=chain_type,\n",
    "                verbose=verbose\n",
    "            )\n",
    "        return chain.run(docs) # summary\n",
    "    \n",
    "    def use_summ_checker_chain(self, texts):\n",
    "        checker_chain = LLMSummarizationCheckerChain(\n",
    "            llm=self.llm,\n",
    "            verbose=False,\n",
    "            max_checks=2\n",
    "        )\n",
    "        return checker_chain.run(texts)\n",
    "\n",
    "    def evaluate(\n",
    "        self,\n",
    "        original_summary,\n",
    "        generated_summary\n",
    "    ):\n",
    "        metric_score = rouge.compute(\n",
    "            predictions=generated_summary,\n",
    "            references=original_summary\n",
    "        )\n",
    "        return metric_score\n",
    "    \n",
    "    def rouge_scorer(\n",
    "        self,\n",
    "        original_summary,\n",
    "        model_summary\n",
    "    ):\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(original_summary, model_summary)\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = Summarization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = summarizer.load_data(\"evidence.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = summarizer.create_docs(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = summarizer.generate_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarizer.generate_summary(\n",
    "    docs,\n",
    "    prompt,\n",
    "    chain_type=ChainTypes.REFINE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary2 = summarizer.use_summ_checker_chain(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"\"\\nAmong internally displaced households reporting having child(ren) 5 years old or younger, 29% reported that they had noticed at least one child in their household losing weight in the 30 days prior to data collection in Ngala LGA, Borno State (19/01/2021). This was compared to 31% of non-displaced households (n=49). In Mafa LGA, 30% of internally displaced households reported noticing at least one child in their household losing weight in the 30 days prior to data collection, compared to 15% of non-displaced households (n=69). In Konduga LGA, 30% of internally displaced households reported noticing at least one child in their household losing weight in the 30 days prior to data collection, compared to 19% of non-displaced households (n=62). In Hawul LGA, 40% of internally displaced households reported noticing at least one child in their household losing weight in the 30 days prior to data collection, compared to 35% of non-displaced households (n=67). In Dikwa LGA, 59% of internally displaced households reported noticing at least one child in their household losing weight in the 30 days prior to data collection, compared to 51%'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_summary = \"Of the 6 assessed LGAs in Borno, in four LGAs, a higher percentage of displaced households have noticed at least one child in their household losing weight in the 30 days prior to data collection than non displaced households with exception to Ngala and Biu LGA. The highest percentage of households noticing the child lose weight was Dikwa LGA (Displaced 59%, Non displaced 51%) followed by Biu LGA (Displaced 37%, Non displaced 46%) and Hawul LGA (Displaced 40%, Non displaced 35%).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1  = summarizer.rouge_scorer(original_summary, summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2  = summarizer.rouge_scorer(original_summary, summary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.5964912280701754, recall=0.41975308641975306, fmeasure=0.49275362318840576),\n",
       " 'rougeL': Score(precision=0.45614035087719296, recall=0.32098765432098764, fmeasure=0.3768115942028985)}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.3160621761658031, recall=0.7530864197530864, fmeasure=0.44525547445255476),\n",
       " 'rougeL': Score(precision=0.22797927461139897, recall=0.5432098765432098, fmeasure=0.32116788321167883)}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
